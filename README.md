# ‚öôÔ∏è Data Engineer
With 3+ years of experience building scalable data platforms across cloud and on-prem environments. Proven expertise in Lakehouse, Data Lake and Data Warehouse architectures, high-volume IoT data (95k+ devices), and end-to-end ETL pipelines. Strong hands-on experience with Python, SQL, PySpark, Airflow, Trino and Docker, with growing focus on Snowflake, Databricks, dbt and Kafka.

---
## üß† Core Skills
* **Data Engineering:** Python, SQL, PySpark, Pandas, Apache Airflow, Trino, dbt  
* **Cloud & Big Data:** AWS (S3, EC2, Lambda, IAM), Databricks, Snowflake, Lakehouse, Delta/Parquet  
* **Databases:** PostgreSQL, SQL Server, Oracle Autonomous DB, MySQL  
* **Analytics & BI:** Power BI, Qlik Sense, Apache Superset  
* **DevOps & CI/CD:** Docker, Git, CI/CD pipelines, Linux  
* **Methodologies:** Agile / Scrum

---
## üéì Education		        		
- B.S., System Analysis and Development | Dom Bosco University 
(_Jul 2023_) [Download Certificate](assets/files/ed-certificates/bachelor-systems-analysis-development-certificate.pdf)

---
## üíº Work Experience
### **Data Engineer @ Spacecom Monitoramento**
*Apr 2023 ‚Äì Jul 2024*
* Owned **end-to-end production batch pipelines**, working closely with stakeholders to translate business requirements into scalable and reliable data solutions.
* Built and maintained a **Big Data Lakehouse on AWS S3**, following **Medallion Architecture (Bronze, Silver, Gold)** using **Delta/Parquet, PySpark, Pandas, SQL, and Trino**.
* Orchestrated, monitored, and optimised ETL workflows with **Apache Airflow**, deploying containerised services using **Docker on AWS EC2**.
* Supported a large-scale production platform ingesting data from **95k+ IoT devices**, processing **hundreds of millions of records per day**.
* Delivered analytics-ready data to **Qlik Sense and Apache Superset dashboards**, improving data reliability, observability, and decision-making.
* Identified and corrected missing steps in production pipelines, significantly improving **data quality and downstream analytics accuracy**.

---
### **Data Engineer Consultant @ wDiscover**
*Jun 2022 ‚Äì May 2024*
* Delivered multiple **end-to-end data engineering projects** as a consultant, collaborating directly with business and technical stakeholders across different industries.
* Integrated and processed data from **payment providers (PagSeguro, Stone, Cielo)**, **IoT agricultural machinery (John Deere)**, APIs, relational databases, Excel/CSV files, and web scraping pipelines.
* Designed and maintained **Data Warehouses** on **SQL Server and Oracle Autonomous Database**, handling data modelling, cleansing, and complex transformations using **Python, Pandas, and SQL**.
* Built and orchestrated **production-ready ETL pipelines** with **Apache Airflow**, deploying solutions using **Docker on Oracle Cloud VMs**.
* Developed **Power BI dashboards** to support operational monitoring and strategic decision-making, enabling stakeholders to track KPIs and business performance.

---
### **Data Analyst @ Itaete Group**
*Jun 2020 ‚Äì Feb 2023*
* Built and maintained data solutions integrating **IoT devices, PostgreSQL, SQL Server, APIs, and Excel/CSV sources** to support operational and analytical use cases.
* Developed and optimised **data pipelines using Python and SQL**, performing data cleansing, transformation, validation, and enrichment with **Pandas**.
* Designed and implemented a **SQL Server Data Warehouse**, enabling reliable reporting and scalable business analytics for internal teams and external clients.
* Created **Power BI and Excel dashboards** to support management decision-making and operational analysis.
* Developed internal systems for **inventory management and financial automation**, including invoice generation and **automated weekly report distribution**, reducing manual effort and errors.

---
### **Data Assistant @ Noster Group**
*Jun 2017 ‚Äì Feb 2018*
* Supported data solutions integrating **telemetry data, SQL Server, APIs, and Excel/CSV files** for operational monitoring and reporting.
* Assisted in training drivers and operational staff on telemetry systems, charging platforms, and equipment usage, ensuring correct system adoption and data accuracy.
* Produced **Excel reports and dashboards**, using **VBA macros** to automate recurring tasks, data consolidation, and basic data manipulation for day-to-day operational analysis.

---
### **IT Assistant @ Noster Group**
*Nov 2014 ‚Äì Nov 2016*
* Provided day-to-day support for **IT infrastructure**, including networks, security, and on-premise systems.
* Performed computer and system maintenance, troubleshooting **hardware and software issues** to ensure operational continuity.
* Supported **database administration tasks**, including basic maintenance, backups, and data organisation.
* Created **Excel reports and dashboards**, leveraging **VBA macros** to automate manual processes, standardise data handling, and improve reporting efficiency.

---
## üöÄ Projects
### IoT Lakehouse Platform (Production)
**Tech:** AWS S3, PySpark, Apache Airflow, Trino, Docker, Delta/Parquet  
- Designed and implemented a **scalable Lakehouse architecture** following the **Medallion (Bronze/Silver/Gold)** pattern.
- Processed **hundreds of millions of IoT records per day** from **90k+ connected devices** with reliable batch ingestion.
- Identified and fixed missing pipeline steps, improving **data reliability by ~15‚Äì20%** and significantly reducing downstream reporting issues.
- Optimised transformations and query layers, reducing **analytics latency by ~20%** for BI consumers.
- Enabled business teams to access **trusted, near-real-time insights**, supporting operational monitoring and strategic decisions at scale.

‚û°Ô∏è *Private Repository:* https://github.com/devzurc/iot-lakehouse

---
### Payments Data Warehouse
**Tech:** Python, SQL, Apache Airflow, SQL Server, Power BI, AWS, Azure  
- Integrated data from **multiple payment providers** (PagSeguro, Stone, Cielo), consolidating fragmented financial sources into a single model.
- Designed and implemented a **Data Warehouse** supporting financial, operational and reconciliation reporting.
- Automated ETL pipelines, reducing **manual data processing effort by ~50%** and improving **data freshness from days to hours**.
- Improved data consistency and validation, decreasing **financial reporting discrepancies by ~20‚Äì30%**.
- Enabled faster, data-driven decision-making for finance and operations teams through **self-service Power BI dashboards**.

‚û°Ô∏è *Private Repository:* https://github.com/devzurc/payments-dwh 

---
### John Deere API Data Pipeline
**Tech:** Python, SQL, Apache Airflow, Oracle Database, Power BI  
- Built a **robust ingestion pipeline** consuming data from the **John Deere REST API**, handling authentication, pagination and failures.
- Modelled and stored operational data in an **Oracle-based Data Warehouse** for fleet and agribusiness analytics.
- Automated daily pipelines with Airflow, improving **data availability by ~40%** compared to manual extraction processes.
- Enabled stakeholders to monitor **equipment performance, usage and operational KPIs** through Power BI dashboards.
- Designed the solution to be **extensible**, allowing new machinery data sources to be onboarded with minimal rework.

‚û°Ô∏è *Private Repository:* https://github.com/devzurc/api-johndeere
<!-- ![EEG Band Discovery](/assets/img/eeg_band_discovery.jpeg) -->

---
## üèÖ Certifications
### English Proficiency
* [IELTS ‚Äì International English Language Testing System](assets/files/ed-certificates/ielts-general-site.pdf)
* [Udemy ‚Äì Ingl√™s Extremo (Intermediate)](https://ude.my/UC-9a9535a4-c479-408a-acd8-1d06318c5eec)

### Data Engineering
* [IBM / Coursera ‚Äì Introduction to Data Engineering](https://www.coursera.org/account/accomplishments/verify/BEJ3LNDRHD9X)
* [DS Academy ‚Äì Fundamentos de Engenharia de Dados](https://mycourse.app/mDey2z4xSWzPUS2T7)
* Alura ‚Äì ETL with SQL Server Integration Services (SSIS)
  * [Data Modeling](https://cursos.alura.com.br/certificate/b1e3dc95-d65d-4ba7-a422-5914475941eb)
  * [Data Transformation](https://cursos.alura.com.br/certificate/56011c99-ecd5-40f1-8647-56469f4bcee8)

### Python & Data Processing
* [Udemy ‚Äì The Complete Python Developer Certification](https://www.udemy.com/certificate/UC-13089b31-ad1b-4532-8d04-ac378596960b/)
* [DS Academy ‚Äì Python for Data Analysis](https://mycourse.app/f5pLpS2UcVbZ66iq8)
* Alura ‚Äì Python for Data Science Track
  * [Python & NumPy](https://cursos.alura.com.br/certificate/74d6c51a-2c05-47f7-9776-c59f0c1682a1)  
  * [Pandas & Data Manipulation](https://cursos.alura.com.br/certificate/87802c24-9028-4dba-986d-2b5b96462e37)  
  * [Pandas I/O & File Formats](https://cursos.alura.com.br/certificate/66b174ad-2f0f-468b-8318-0f44ec4d9549)  
  * [Pandas Fundamentals](https://cursos.alura.com.br/certificate/fc1e7983-1a3a-45f2-91a2-ea7a11ef2523)  
  * [Python for Data Science ‚Äì Foundations](https://cursos.alura.com.br/certificate/44e0fed8-4f87-4824-94b8-bdca55d01843)  

### Cloud Computing (AWS)
* [Coursera - AWS Cloud Practitioner Essentials](https://www.coursera.org/account/accomplishments/verify/GR33NJ7P5QAD)
* [Udemy ‚Äì AWS for Beginners](https://ude.my/UC-d6419758-f145-4661-9252-4042381674ee)

### SQL & Databases
* Alura ‚Äì SQL Server (2017 & 2019)
  * [Introduction to SQL](https://cursos.alura.com.br/certificate/c045f437-8705-460b-9536-c39f61bb7928)
  * [Advanced Queries](https://cursos.alura.com.br/certificate/4fcdf8c2-cd7d-43f4-9da0-2fac68c50f5d)
  * [SQL Server 2019](https://cursos.alura.com.br/certificate/d34e618a-1f0a-44dd-a51c-54467402a53a)
* [Alura ‚Äì SQL with MySQL](https://cursos.alura.com.br/certificate/81df51fb-96b1-4897-8ba9-789f0f356776)

### Workflow Orchestration
* Alura ‚Äì Apache Airflow
  * [Data Extraction](https://cursos.alura.com.br/certificate/f3be1257-e150-450f-a670-7fcd94bc6ed0)
  * [Pipeline Orchestration](https://cursos.alura.com.br/certificate/da8b7956-c3c7-4b2a-945d-8e28ae61239b)

### Business Intelligence & Analytics (Qlik Sense)
* Alura ‚Äì Qlik Sense Track
  * [Introduction to Qlik Sense](https://cursos.alura.com.br/certificate/e9d0d2cf-dd27-449f-8f7f-cdb83dbfc2da)
  * [SQL Connections](https://cursos.alura.com.br/certificate/c66a0621-fc9f-4ef1-ab02-e5c27c3a4260)
  * [Data Analysis](https://cursos.alura.com.br/certificate/54d08254-3753-4cde-ae60-142e828a3bb6)
  * [Data Manipulation](https://cursos.alura.com.br/certificate/2cf4822e-a0ef-4342-b081-edab63006522)
  * [Advanced Expressions](https://cursos.alura.com.br/certificate/ddf46038-66fa-47b7-a763-ea19c6a51dbc)
  * [Business Intelligence & Data Warehouse](https://cursos.alura.com.br/certificate/8e1d56d2-d07b-4419-803c-8a89d7459a98)

### Agile & Methodology
* [Scrum Foundation Professional Certificate (SFPC‚Ñ¢)](https://www.credly.com/badges/3c1a2135-0ef4-4af4-9905-f716aa45a520/linked_in_profile)

---
## üìù Publications
- [Data Engineer Blog](https://medium.com/@dev.lucascruz)
1. [Python Concepts.](https://medium.com/@dev.lucascruz)
2. [Lakehouse Medalion Architecture.](https://medium.com/@dev.lucascruz)

---
## üë• Let‚Äôs Connect
- **Email:** *dev.lucascruz@gmail.com*

- <a href="https://www.linkedin.com/in/lucas-cruz/" target="_blank" rel="noopener noreferrer">‚û°Ô∏è Access LinkedIn</a>
---
- <a href="assets/files/cv/eng.pdf" target="_blank" rel="noopener noreferrer">‚¨áÔ∏è Download CV (ENG)</a>
- <a href="assets/files/cv/ptbr.pdf" target="_blank" rel="noopener noreferrer">‚¨áÔ∏è Download CV (PT-BR)</a>